{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN2XG8GjQNuqjQH2v3WpiKJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wUscRjZDbo1k"},"outputs":[],"source":["from google.colab import drive\n","# Mount google drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/SLU/NLP/2/\n","%ls"]},{"cell_type":"code","source":["import pandas as pd\n","# Load dataset file\n","df_total = pd.read_csv(\"train.tsv\", sep='\\t', names=[\"word\", \"tag\"])\n","df_total.head()"],"metadata":{"id":"yTCe8by_bwwG","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1663888277336,"user_tz":300,"elapsed":888,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"outputId":"334e9b09-df08-4bfc-a5ea-db9f693d298b"},"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    word tag\n","0  ansin   N\n","1      )   N\n","2     tá   N\n","3   níos   N\n","4     lú   N"],"text/html":["\n","  <div id=\"df-ddac74f7-1f16-4dd7-9721-7757346b42fb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ansin</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>)</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>tá</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>níos</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>lú</td>\n","      <td>N</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddac74f7-1f16-4dd7-9721-7757346b42fb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ddac74f7-1f16-4dd7-9721-7757346b42fb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ddac74f7-1f16-4dd7-9721-7757346b42fb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["# df2 = df_total[:15000]\n","df2 = df_total.copy()\n","df2.describe()\n","print((df2['tag'].value_counts()))\n","lbl = df2['tag'].value_counts().max()\n","max_label = df2['tag'][lbl]\n","max_label"],"metadata":{"id":"sOHOdisPbylD","colab":{"base_uri":"https://localhost:8080/","height":145},"executionInfo":{"status":"ok","timestamp":1663888281269,"user_tz":300,"elapsed":3937,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"outputId":"412c730f-3231-48fd-f6eb-32c9f3ced0d4"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["N    4339849\n","S     493102\n","U     165818\n","H      40569\n","T      17721\n","Name: tag, dtype: int64\n"]},{"output_type":"execute_result","data":{"text/plain":["'N'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["# converting input shape for tagger\n","df3 = [[(df2.loc[i,'word'], df2.loc[i,'tag'])] for i in range(len(df2))]"],"metadata":{"id":"vffnjryhdXLc","executionInfo":{"status":"ok","timestamp":1663888443618,"user_tz":300,"elapsed":162356,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["# creating train and test datasets\n","split = int(len(df3)*0.9)\n","train = df3[:split]\n","test = df3[split:]\n","len(train)"],"metadata":{"id":"qIubdvydeLKV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663888443619,"user_tz":300,"elapsed":22,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"outputId":"00acf7d2-e1c0-4ecd-dc8e-07e4d8682aec"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4551353"]},"metadata":{},"execution_count":82}]},{"cell_type":"markdown","source":["**Unigram tagger**"],"metadata":{"id":"3UflkEvQ_O5x"}},{"cell_type":"code","source":["# unigram tagger \n","import nltk\n","unigram_tagger = nltk.UnigramTagger(train)\n","print(\"Unigram tagger accuracy without backoff tagger is: \", unigram_tagger.accuracy(test))"],"metadata":{"id":"Gw5g8u4OdSE_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663888458712,"user_tz":300,"elapsed":15110,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"outputId":"5e7a52c8-1549-4bb1-9c98-8a71e2f2d484"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Unigram tagger accuracy without backoff tagger is:  0.8941875318861157\n"]}]},{"cell_type":"code","source":["from nltk.tag import SequentialBackoffTagger\n","from nltk.tag import DefaultTagger \n","from nltk.tag import UnigramTagger \n","\n","back_tagger = DefaultTagger(max_label)\n","unigram_tagger2 = UnigramTagger(train, backoff = back_tagger)\n","print(\"Unigram tagger accuracy with backoff tagger is: \", unigram_tagger2.accuracy(test))"],"metadata":{"id":"p2bbyuO-cri0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663888474161,"user_tz":300,"elapsed":15453,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"outputId":"9ee6e29f-8369-4f8b-9807-b967297d6ce3"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Unigram tagger accuracy with backoff tagger is:  0.907707244920962\n"]}]},{"cell_type":"markdown","source":["**RNN**"],"metadata":{"id":"y3q7YVTtObTF"}},{"cell_type":"code","source":["df_rnn = df_total[:15000]\n","df_rnn2 = [[(df2.loc[i,'word'], df2.loc[i,'tag'])] for i in range(len(df_rnn))]\n","\n","\n","vocab = list(df_rnn['word'])\n","vocab.append('<PAD>')\n","\n","tags = list(df_rnn['tag'])\n","tags.append('<PAD>')\n","\n","print(len(vocab))\n","print(len(tags))"],"metadata":{"id":"vGx_KnyxObxU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663888664505,"user_tz":300,"elapsed":1055,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"outputId":"7a643858-0ec3-4d9c-c603-75e53d047be0"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["15001\n","15001\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","max_len = 2\n","word2index = {w: i for i, w in enumerate(vocab)}\n","tag2index = {t: i for i, t in enumerate(tags)}\n","onehot = [[word2index[w[0]] for w in s] for s in df_rnn2]\n","X = pad_sequences(maxlen=max_len, sequences=onehot, padding=\"post\", value=len(vocab)-1)"],"metadata":{"id":"OIwqDGP7NmP-","executionInfo":{"status":"ok","timestamp":1663888665437,"user_tz":300,"elapsed":3,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["print(len(X))\n","print(type(X))\n","print(X.shape)\n","X[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRbGFM-EAk_D","executionInfo":{"status":"ok","timestamp":1663888667964,"user_tz":300,"elapsed":1127,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"outputId":"d65189ba-a7ec-4309-a8d1-30786553f377"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["15000\n","<class 'numpy.ndarray'>\n","(15000, 2)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([14746, 15000], dtype=int32)"]},"metadata":{},"execution_count":106}]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","\n","onehot_y = [[tag2index[w[1]] for w in s] for s in df_rnn2]\n","y = pad_sequences(maxlen=max_len, sequences=onehot_y, padding=\"post\", value=tag2index[\"<PAD>\"])\n","y = to_categorical(y, num_classes=len(tags))"],"metadata":{"id":"wZzucfblOVrv","executionInfo":{"status":"ok","timestamp":1663888681235,"user_tz":300,"elapsed":1084,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["print(len(y))\n","print(type(y))\n","y.shape"],"metadata":{"id":"Gx7nsB0WDtHc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663888681236,"user_tz":300,"elapsed":4,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"outputId":"2bed6369-06c2-4195-8480-a3f1668d94a8"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["15000\n","<class 'numpy.ndarray'>\n"]},{"output_type":"execute_result","data":{"text/plain":["(15000, 2, 15001)"]},"metadata":{},"execution_count":110}]},{"cell_type":"code","source":["# creaint train and test sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n","\n","print(len(X_train))\n","print(len(X_test))\n","print(len(y_train))\n","print(len(y_test))\n","print(X_train.shape)\n","print(X_test.shape)"],"metadata":{"id":"dRhYS54USOVX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663888687150,"user_tz":300,"elapsed":3082,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"outputId":"778220f9-a552-4210-8d12-6ac58aecbaf9"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["13500\n","1500\n","13500\n","1500\n","(13500, 2)\n","(1500, 2)\n"]}]},{"cell_type":"code","source":["%pip install -q -U keras-tuner\n","import keras_tuner as kt"],"metadata":{"id":"LtqJfAbXCoh2","executionInfo":{"status":"ok","timestamp":1663888691010,"user_tz":300,"elapsed":3867,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional \n","\n","\n","def model_builder(hp):\n","  model = keras.Sequential()\n","\n","  # Tune the number of units in the first Dense layer\n","  # Choose an optimal value between 32-512\n","  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n","  model.add(Embedding(input_dim=len(vocab), output_dim=50, input_length=max_len))\n","  model.add(Bidirectional(LSTM(units=hp_units, return_sequences=True, recurrent_dropout=0.1)))\n","  model.add(TimeDistributed(Dense(len(tags), activation=\"softmax\")))\n","\n","\n","  # Tune the learning rate for the optimizer\n","  # Choose an optimal value from 0.01, 0.001, or 0.0001\n","  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]) \n","  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","  \n","\n","  return model"],"metadata":{"id":"bQUQQPv3GcbZ","executionInfo":{"status":"ok","timestamp":1663888691011,"user_tz":300,"elapsed":16,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["tuner = kt.Hyperband(model_builder,\n","                     objective='val_accuracy',\n","                     max_epochs=3,\n","                     factor=3)\n","stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"],"metadata":{"id":"KxT0yxwtC6Tc","executionInfo":{"status":"ok","timestamp":1663888692030,"user_tz":300,"elapsed":1034,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cd718252-0d4d-4a86-eee2-4e5e7b3224ea"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"code","source":["stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"],"metadata":{"id":"7eGxoUCeGhvx","executionInfo":{"status":"ok","timestamp":1663888696231,"user_tz":300,"elapsed":4,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["tuner.search(X_train, y_train, epochs= 3, validation_split=0.2, callbacks=[stop_early])\n","\n","# Get the optimal hyperparameters\n","best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","print(\"The optimal number of units in the first densely-connected layer is: \", best_hps.get('units') , \" and the optimal learning rate for the optimizer is \"\n",", best_hps.get('learning_rate'))"],"metadata":{"id":"U8H7x_JxGkop","executionInfo":{"status":"ok","timestamp":1663889731411,"user_tz":300,"elapsed":915406,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"54e50e0d-b9b7-44b6-d757-32641c172ae7"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 42 Complete [00h 01m 15s]\n","val_accuracy: 0.9444444179534912\n","\n","Best val_accuracy So Far: 0.9972222447395325\n","Total elapsed time: 00h 15m 15s\n","The optimal number of units in the first densely-connected layer is:  96  and the optimal learning rate for the optimizer is  0.001\n"]}]},{"cell_type":"code","source":["# Build the model with the optimal hyperparameters and train it on the data for number of epochs\n","model = tuner.hypermodel.build(best_hps)\n","history = model.fit(X_train, y_train, epochs= 5, validation_split=0.2)\n","\n","val_acc_per_epoch = history.history['val_accuracy']\n","best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n","print('Best epoch: %d' % (best_epoch,))"],"metadata":{"id":"QlNo-1XiJ33K","executionInfo":{"status":"ok","timestamp":1663888524775,"user_tz":300,"elapsed":44090,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6fe7a47b-462c-49a8-b0b6-453c11178b9c"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","225/225 [==============================] - 7s 18ms/step - loss: 2.4649 - accuracy: 0.8914 - val_loss: 0.2235 - val_accuracy: 0.9347\n","Epoch 2/5\n","225/225 [==============================] - 5s 21ms/step - loss: 0.1983 - accuracy: 0.9349 - val_loss: 0.1780 - val_accuracy: 0.9489\n","Epoch 3/5\n","225/225 [==============================] - 6s 29ms/step - loss: 0.1345 - accuracy: 0.9574 - val_loss: 0.1776 - val_accuracy: 0.9478\n","Epoch 4/5\n","225/225 [==============================] - 6s 26ms/step - loss: 0.1106 - accuracy: 0.9621 - val_loss: 0.1887 - val_accuracy: 0.9461\n","Epoch 5/5\n","225/225 [==============================] - 4s 19ms/step - loss: 0.1042 - accuracy: 0.9622 - val_loss: 0.1888 - val_accuracy: 0.9458\n","Best epoch: 2\n"]}]},{"cell_type":"markdown","source":["**HMM**"],"metadata":{"id":"rO_yixYs3ZlQ"}},{"cell_type":"code","source":["# Import the toolkit and tags\n","import nltk\n","\n","# Import HMM module\n","from nltk.tag import hmm\n","\n","# Setup a trainer with default(None) values and train with the data\n","tagger = nltk.HiddenMarkovModelTagger.train(train)\n","# Prints the basic data about the tagger\n","print(tagger)"],"metadata":{"id":"-EA_4Onr3Yzs","executionInfo":{"status":"ok","timestamp":1663888541341,"user_tz":300,"elapsed":16583,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1c5e6e5-ece0-468a-9c6e-9812bd8c5a07"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["<HiddenMarkovModelTagger 5 states and 118706 output symbols>\n"]}]},{"cell_type":"code","source":["print(tagger.accuracy(test))"],"metadata":{"id":"gxq7t4mI9qyA","executionInfo":{"status":"ok","timestamp":1663888615291,"user_tz":300,"elapsed":73954,"user":{"displayName":"Mohammad Amir Salari","userId":"03955375020079249046"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"702e4eb3-d9df-47b0-cbf6-7bad7f08e911"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9078239134991477\n"]}]}]}