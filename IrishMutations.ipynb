{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_F41Ez3cO7xN"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gecQSCrBPAXA"
      },
      "outputs": [],
      "source": [
        "fn = r\"../train.tsv\"\n",
        "handle  = open(fn, \"r\")\n",
        "tokens = list()\n",
        "\n",
        "for line in handle:\n",
        "  entry = line.strip().split(\"\\t\")\n",
        "  tokens.append( ( entry[0], entry[1]) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9z2j__fcWeVS"
      },
      "outputs": [],
      "source": [
        "def flat2sent(sents, end = \"<S>\"):\n",
        "  \"\"\"This function turns flat array (1d) of sentences into list of sentences (2d).\n",
        "\n",
        "    End indicates the last token of the sentence.\n",
        "  Args:\n",
        "      sents (): 1d array of sentences\n",
        "      end (str, optional): start of sentence symbol. Defaults to \"<S>\".\n",
        "\n",
        "  Returns:\n",
        "      _type_: 2d array (list of sentences)\n",
        "  \"\"\"\n",
        "  list_of_sent = list()\n",
        "  sent = []\n",
        "  for char in sents:\n",
        "    sent.append(char)\n",
        "    if char[0] == end:\n",
        "      list_of_sent.append(sent)\n",
        "      sent = []\n",
        "  return list_of_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Yr5O3vVLRJz7"
      },
      "outputs": [],
      "source": [
        "#train-split for sentences\n",
        "train_index = int([ind for (ind, token) in enumerate(tokens) if token[0] == \"<S>\"][-1]*0.8)\n",
        "sentTrain = flat2sent ( tokens[:train_index] )\n",
        "sentTest = flat2sent( tokens[train_index:] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUklCzyc2gei",
        "outputId": "b9ae8ec2-5f98-4365-dc3f-3da68f4e4abe"
      },
      "outputs": [],
      "source": [
        "# map of n preceding words to mutations\n",
        "LAGGED_PRECEDE_MUTATE = defaultdict(lambda: defaultdict(int))\n",
        "def lag_to_create_n_grams(sent: list, ngram=1):\n",
        "    sent = [(\"<IGNORE>\", \"N\") for _ in range(ngram)] + sent #padding in front\n",
        "    for ind, piece in enumerate(sent):\n",
        "        if ind < ngram:\n",
        "            continue\n",
        "        for n in range(1,ngram+1):\n",
        "\n",
        "            prev_phrase = ' '.join( [w[0] for w in sent[ind-n: ind]] )\n",
        "            if \"<IGNORE>\" in prev_phrase:\n",
        "                continue\n",
        "            tag = piece[1]\n",
        "            LAGGED_PRECEDE_MUTATE[prev_phrase][tag] += 1\n",
        "            LAGGED_PRECEDE_MUTATE[prev_phrase][\"occurence\"] += 1\n",
        "            #if (prev_phrase == \"\"):\n",
        "            #    print(ind, n, prev_phrase, tag, piece)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# example: The weather is nice with tag D N V A with ngram = 2\n",
        "# {The: {N: 1}, weather: {V: 1}, The weather: {V : 1}, is: {A: 1}, weather is: {A: 1}\n",
        "#lag_to_create_n_grams([(\"The\", \"D\"), (\"weather\", \"N\"), (\"is\", \"V\"), (\"nice\", \"A\")], ngram=2)\n",
        "#creaeting bigram\n",
        "for sent in sentTrain:\n",
        "    lag_to_create_n_grams(sent,2)\n",
        "#LAGGED_PRECEDE_MUTATE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LXJYboMNnjlg"
      },
      "outputs": [],
      "source": [
        "# building the transition matrix\n",
        "def prob_from_count_dict(count_dict,k1,k2):\n",
        "    try:\n",
        "        return count_dict[k1][k2]/count_dict[k1][\"occurence\"]\n",
        "    except ZeroDivisionError:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "TAG_TO_WORD_COUNT =defaultdict(lambda: defaultdict(int))\n",
        "INITIAL_DISTRIBUTION_COUNT = defaultdict(int)\n",
        "#if we were to generate a mutation, how many of it is word w_i\n",
        "def build_emission(sent: list):\n",
        "    for ind, piece in enumerate(sent):\n",
        "\n",
        "        word = piece[0]\n",
        "        tag = piece[1]\n",
        "\n",
        "        TAG_TO_WORD_COUNT[tag][word] += 1\n",
        "        TAG_TO_WORD_COUNT[tag][\"occurence\"] += 1\n",
        "        if ind == 0:\n",
        "            INITIAL_DISTRIBUTION_COUNT[tag] +=1\n",
        "            INITIAL_DISTRIBUTION_COUNT[\"all\"] += 1\n",
        "\n",
        "\n",
        "        #if (prev_phrase == \"\"):\n",
        "        #    print(ind, n, prev_phrase, tag, piece)\n",
        "for sent in sentTrain:\n",
        "    build_emission(sent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "NKP5gtMBHnfK"
      },
      "outputs": [],
      "source": [
        "def argmax(Vit_matrix, ind, phrase):\n",
        "    ans = -1\n",
        "    bestTag = None\n",
        "    for t in [\"N\", \"S\", \"U\", \"T\", \"H\"]:\n",
        "        #prob_from_count_dict(count_dict,k1,k2)\n",
        "        temp = Vit_matrix[t][ind-1]*prob_from_count_dict(LAGGED_PRECEDE_MUTATE,phrase,t)\n",
        "        #print(temp)\n",
        "        #print(prob_from_count_dict(LAGGED_PRECEDE_MUTATE, phrase, t))\n",
        "        #print(Vit_matrix[t][ind-1])\n",
        "        if temp > ans:\n",
        "            ans = temp\n",
        "            bestTag = t\n",
        "        #print(t, end=' ')\n",
        "    return ans, bestTag\n",
        "\n",
        "def viterbi(sent):\n",
        "    best_tags = []\n",
        "    Vit_matrix = defaultdict(lambda: defaultdict(float)) #V[state][word]\n",
        "    for t in [\"N\",\"S\",\"U\",\"T\",\"H\"]:\n",
        "        # initial probability distribution * emission\n",
        "\n",
        "        start_state_prob = INITIAL_DISTRIBUTION_COUNT[t]/INITIAL_DISTRIBUTION_COUNT[\"all\"]\n",
        "\n",
        "        #prob_from_count_dict(count_dict,k1,k2)\n",
        "        emission = prob_from_count_dict(TAG_TO_WORD_COUNT, t, sent[0][0])\n",
        "\n",
        "        Vit_matrix[t][0] = start_state_prob * emission\n",
        "    for i in range(1, len(sent)):\n",
        "        for t in [\"N\", \"S\", \"U\", \"T\", \"H\"]:\n",
        "            phrase = sent[i-1][0] #TODO: dynamically chose the prhase could be 2 word precede, 1 word precede\n",
        "            val,tag = argmax(Vit_matrix, i, phrase)\n",
        "            emission = prob_from_count_dict(TAG_TO_WORD_COUNT, t,sent[i][0])\n",
        "            Vit_matrix[t][i] = val*emission # transimition_matrix *emission probability\n",
        "            best_tags.append((i, tag))\n",
        "    return Vit_matrix, best_tags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1, 'N'), (1, 'N'), (1, 'N'), (1, 'N'), (1, 'N'), (2, 'N'), (2, 'N'), (2, 'N'), (2, 'N'), (2, 'N'), (3, 'N'), (3, 'N'), (3, 'N'), (3, 'N'), (3, 'N'), (4, 'N'), (4, 'N'), (4, 'N'), (4, 'N'), (4, 'N')]\n"
          ]
        }
      ],
      "source": [
        "v, bt = viterbi(sentTrain[241])\n",
        "sentTrain[241]\n",
        "#TAG_TO_WORD_COUNT[\"N\"][\"cosaint\"]/TAG_TO_WORD_COUNT[\"N\"][\"occurence\"]\n",
        "#print( prob_from_count_dict(TAG_TO_WORD_COUNT, \"T\", \"cosaint\") )\n",
        "#LAGGED_PRECEDE_MUTATE\n",
        "\n",
        "print(bt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.viterbi.<locals>.<lambda>()>,\n",
              "            {'N': defaultdict(str, {1: 'N', 2: 'N', 3: 'N', 4: 'N'}),\n",
              "             'S': defaultdict(str, {1: 'N', 2: 'N', 3: 'N', 4: 'N'}),\n",
              "             'U': defaultdict(str, {1: 'N', 2: 'N', 3: 'N', 4: 'N'}),\n",
              "             'T': defaultdict(str, {1: 'N', 2: 'N', 3: 'N', 4: 'N'}),\n",
              "             'H': defaultdict(str, {1: 'N', 2: 'N', 3: 'N', 4: 'N'})})"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCft_nGAO7xO"
      },
      "outputs": [],
      "source": [
        "# argument sent is a list of [token,label] pairs; return number of correctly predicted labels\n",
        "def predict_from_scratch(sent, model=None):\n",
        "  correct = 0\n",
        "  for token in sent:\n",
        "    guess = random.choice(['S','U','T','H','N'])\n",
        "    if guess == token[1]:\n",
        "      correct += 1\n",
        "  return correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30j88uv7O7xP"
      },
      "outputs": [],
      "source": [
        "# argument sent is a list of [token,label] pairs; return number of correctly predicted labels\n",
        "def predict_anything_goes(sent):\n",
        "  correct = 0\n",
        "  for token in sent:\n",
        "    guess = 'N'\n",
        "    if guess == token[1]:\n",
        "      correct += 1\n",
        "  return correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7iSShNrO7xQ"
      },
      "outputs": [],
      "source": [
        "#sentence is a list of tuples(x,y)\n",
        "def evaluate():\n",
        "  total = 0\n",
        "  correct_from_scratch = 0\n",
        "  correct_anything_goes = 0\n",
        "  testfile = open('test.tsv', 'r')\n",
        "  sentence = []\n",
        "  for line in testfile:\n",
        "    total += 1\n",
        "    pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
        "    if pieces[0]=='<S>':\n",
        "      correct_from_scratch += predict_from_scratch(sentence)\n",
        "      correct_anything_goes += predict_anything_goes(sentence)\n",
        "      sentence = []\n",
        "    else:\n",
        "      sentence.append(pieces)\n",
        "  correct_from_scratch += predict_from_scratch(sentence)\n",
        "  correct_anything_goes += predict_anything_goes(sentence)\n",
        "  return (correct_from_scratch/total, correct_anything_goes/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDQEerHcO7xR",
        "outputId": "2c0ca723-cc29-42cc-fb54-4d190d3d354d"
      },
      "outputs": [],
      "source": [
        "evaluate()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
