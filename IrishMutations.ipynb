{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_F41Ez3cO7xN"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gecQSCrBPAXA"
      },
      "outputs": [],
      "source": [
        "fn = r\"train.tsv\"\n",
        "handle  = open(fn, \"r\")\n",
        "tokens = list()\n",
        "\n",
        "for line in handle:\n",
        "  entry = line.strip().split(\"\\t\")\n",
        "  tokens.append( ( entry[0], entry[1]) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEMYRlQ0QoYA",
        "outputId": "bcae3be9-9816-4b70-a716-79c52366ca02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'N': 8584022, 'S': 973469, 'U': 327110, 'H': 80504, 'T': 34895})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#frequencies of all the mutations\n",
        "frequency = Counter([t for (w,t) in tokens])\n",
        "frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9z2j__fcWeVS"
      },
      "outputs": [],
      "source": [
        "def flat2sent(sents, end = \"<S>\"):\n",
        "  \"\"\"This function turns flat array (1d) of sentences into list of sentences (2d).\n",
        "\n",
        "    End indicates start of sentence.\n",
        "  Args:\n",
        "      sents (): 1d array of sentences\n",
        "      end (str, optional): start of sentence symbol. Defaults to \"<S>\".\n",
        "\n",
        "  Returns:\n",
        "      _type_: 2d array (list of sentences)\n",
        "  \"\"\"\n",
        "  list_of_sent = list()\n",
        "  sent = []\n",
        "  for char in sents:\n",
        "    sent.append(char)\n",
        "    if char[0] == end:\n",
        "      list_of_sent.append(sent)\n",
        "      sent = []\n",
        "  return list_of_sent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Yr5O3vVLRJz7"
      },
      "outputs": [],
      "source": [
        "#train-split for sentences\n",
        "train_index = int([ind for (ind, token) in enumerate(tokens) if token[0] == \"<S>\"][-1]*0.8)\n",
        "sentTrain = flat2sent ( tokens[:train_index] )\n",
        "sentTest = flat2sent( tokens[train_index:] )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUklCzyc2gei",
        "outputId": "b9ae8ec2-5f98-4365-dc3f-3da68f4e4abe"
      },
      "outputs": [],
      "source": [
        "# map of n preceding words to mutations\n",
        "LAGGED_PRECEDE_MUTATE = defaultdict(lambda: defaultdict(int))\n",
        "def lag_to_create_n_grams(sent: list, ngram=1):\n",
        "    sent = [(\"<IGNORE>\", \"N\") for _ in range(ngram)] + sent #padding in front\n",
        "    for ind, piece in enumerate(sent):\n",
        "        if ind < ngram:\n",
        "            continue\n",
        "        for n in range(1,ngram+1):\n",
        "\n",
        "            prev_phrase = ' '.join( [w[0] for w in sent[ind-n: ind]] )\n",
        "            if \"<IGNORE>\" in prev_phrase:\n",
        "                continue\n",
        "            tag = piece[1]\n",
        "            LAGGED_PRECEDE_MUTATE[prev_phrase][tag] += 1\n",
        "            LAGGED_PRECEDE_MUTATE[prev_phrase][\"occurence\"] += 1\n",
        "            #if (prev_phrase == \"\"):\n",
        "            #    print(ind, n, prev_phrase, tag, piece)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# example: The weather is nice with tag D N V A with ngram = 2\n",
        "# {The: {N: 1}, weather: {V: 1}, The weather: {V : 1}, is: {A: 1}, weather is: {A: 1}\n",
        "#lag_to_create_n_grams([(\"The\", \"D\"), (\"weather\", \"N\"), (\"is\", \"V\"), (\"nice\", \"A\")], ngram=2)\n",
        "\n",
        "for sent in sentTrain:\n",
        "    lag_to_create_n_grams(sent,3)\n",
        "#LAGGED_PRECEDE_MUTATE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LXJYboMNnjlg"
      },
      "outputs": [],
      "source": [
        "# building the transition matrix\n",
        "def prob_tag_givenWord(t,w):\n",
        "    try:\n",
        "        return LAGGED_PRECEDE_MUTATE[w][t]/LAGGED_PRECEDE_MUTATE[w][\"occurence\"]\n",
        "    except ZeroDivisionError:\n",
        "        return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2343\n"
          ]
        }
      ],
      "source": [
        "prob_tag_givenWord(\"T\",\"bean\")\n",
        "print(LAGGED_PRECEDE_MUTATE[\"bean\"][\"occurence\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7999999"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "TAG_TO_WORD =defaultdict(lambda: defaultdict(int))\n",
        "INITIAL_DISTRIBUTION_PROB = defaultdict(int)\n",
        "#if we were to generate a mutation, how many of it is word w_i\n",
        "def build_emission(sent: list):\n",
        "    for ind, piece in enumerate(sent):\n",
        "\n",
        "        word = piece[0]\n",
        "        tag = piece[1]\n",
        "\n",
        "        TAG_TO_WORD[tag][word] += 1\n",
        "        TAG_TO_WORD[tag][\"occurence\"] += 1\n",
        "        if ind == 0:\n",
        "            INITIAL_DISTRIBUTION_PROB[tag] +=1\n",
        "\n",
        "\n",
        "        #if (prev_phrase == \"\"):\n",
        "        #    print(ind, n, prev_phrase, tag, piece)\n",
        "for sent in sentTrain:\n",
        "    build_emission(sent)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_initial_distribution_prob(initial_count):\n",
        "    total = sum(initial_count[i] for i in initial_count)\n",
        "    print(total)\n",
        "    return dict([(k,initial_count[k]/total) for k in initial_count])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "316834\n"
          ]
        }
      ],
      "source": [
        "INITIAL_DISTRIBUTION_PROB = get_initial_distribution_prob(\n",
        "    INITIAL_DISTRIBUTION_PROB)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NKP5gtMBHnfK"
      },
      "outputs": [],
      "source": [
        "def argmax(Vit_matrix, tag, ind, phrase):\n",
        "    ans = -1\n",
        "    for t in [\"N\", \"S\", \"U\", \"T\", \"H\"]:\n",
        "        temp = Vit_matrix[t][ind-1]*LAGGED_PRECEDE_MUTATE[phrase][t]\n",
        "        if temp > ans:\n",
        "            ans = temp\n",
        "        print(t, end=' ')\n",
        "    return ans\n",
        "\n",
        "def viterbi(sent):\n",
        "    Vit_matrix = defaultdict(lambda: defaultdict(float)) #V[state][word]\n",
        "    for t in [\"N\",\"S\",\"U\",\"T\",\"H\"]:\n",
        "        # initial probability distribution * emission\n",
        "        print(INITIAL_DISTRIBUTION_PROB[t])\n",
        "        print(TAG_TO_WORD[t][sent[0]])\n",
        "        Vit_matrix[t][0] = INITIAL_DISTRIBUTION_PROB[t] * TAG_TO_WORD[t][sent[0]]\n",
        "    for i in range(1, len(sent)):\n",
        "        for t in [\"N\", \"S\", \"U\", \"T\", \"H\"]:\n",
        "            phrase = sent[i-1] #TODO: dynamically chose the prhase could be 2 word precede, 1 word precede\n",
        "            val = argmax(Vit_matrix, t, i, phrase)\n",
        "            Vit_matrix[t][i] = val*TAG_TO_WORD[t][sent[i]] # transimition_matrix *emission probability\n",
        "    return Vit_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.901251128351124\n",
            "0\n",
            "0.09597770441303648\n",
            "0\n",
            "0.0016728002676480427\n",
            "0\n",
            "7.259321916208487e-05\n",
            "0\n",
            "0.0010257737490294602\n",
            "0\n",
            "N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H N S U T H "
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('cosaint', 'N'), ('uiscí', 'N'), ('nádúrtha', 'N'), ('.', 'N'), ('<S>', 'N')]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "viterbi(sentTrain[241])\n",
        "sentTrain[241]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCft_nGAO7xO"
      },
      "outputs": [],
      "source": [
        "# argument sent is a list of [token,label] pairs; return number of correctly predicted labels\n",
        "def predict_from_scratch(sent, model=None):\n",
        "  correct = 0\n",
        "  for token in sent:\n",
        "    guess = random.choice(['S','U','T','H','N'])\n",
        "    if guess == token[1]:\n",
        "      correct += 1\n",
        "  return correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30j88uv7O7xP"
      },
      "outputs": [],
      "source": [
        "# argument sent is a list of [token,label] pairs; return number of correctly predicted labels\n",
        "def predict_anything_goes(sent):\n",
        "  correct = 0\n",
        "  for token in sent:\n",
        "    guess = 'N'\n",
        "    if guess == token[1]:\n",
        "      correct += 1\n",
        "  return correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7iSShNrO7xQ"
      },
      "outputs": [],
      "source": [
        "#sentence is a list of tuples(x,y)\n",
        "def evaluate():\n",
        "  total = 0\n",
        "  correct_from_scratch = 0\n",
        "  correct_anything_goes = 0\n",
        "  testfile = open('test.tsv', 'r')\n",
        "  sentence = []\n",
        "  for line in testfile:\n",
        "    total += 1\n",
        "    pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
        "    if pieces[0]=='<S>':\n",
        "      correct_from_scratch += predict_from_scratch(sentence)\n",
        "      correct_anything_goes += predict_anything_goes(sentence)\n",
        "      sentence = []\n",
        "    else:\n",
        "      sentence.append(pieces)\n",
        "  correct_from_scratch += predict_from_scratch(sentence)\n",
        "  correct_anything_goes += predict_anything_goes(sentence)\n",
        "  return (correct_from_scratch/total, correct_anything_goes/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDQEerHcO7xR",
        "outputId": "2c0ca723-cc29-42cc-fb54-4d190d3d354d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.191809, 0.819613)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
