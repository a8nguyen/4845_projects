{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fCWxCwrekBVx",
        "HvS8ncVwgtFz",
        "fWWYjsXLK8Zw"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a8nguyen/4845_projects/blob/main/nlp5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFeg-Zqpe6AV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, GRU\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from numpy import argmax\n",
        "\n",
        "\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "SvkvflzkJOmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading Dataset**"
      ],
      "metadata": {
        "id": "fCWxCwrekBVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filePath):\n",
        "  data_cwe = open(filePath, 'r').read().lower()\n",
        "  return data_cwe"
      ],
      "metadata": {
        "id": "5gVTam4ukEQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining Preprocessing Class**"
      ],
      "metadata": {
        "id": "HvS8ncVwgtFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Language_Translation_Model:\n",
        "  def __init__(self, lang=\"\") -> None:\n",
        "    self.lang = lang\n",
        "    self.all_Unique_Characters = None\n",
        "    self.length_all_Unique_Characters = None\n",
        "    self.length_max_sentence = None\n",
        "    #self.sentenceArray_to_OHE = None\n",
        "    self.char_to_num = None\n",
        "    self.num_to_char = None\n",
        "    # self.ASCII_Chars = ' !\"\\'(),-.0123456789:;?abcdefghijklmnopqrstuvwxyz'\n",
        "  \n",
        "  def sentence_to_array(self, sentence):\n",
        "    sentenceArray = [self.char_to_num[char] for char in sentence]\n",
        "    #padding = [0 for _ in range(self.length_all_Unique_Characters-len(sentenceArray))]\n",
        "    #sentenceArray = np.array(sentenceArray+padding)\n",
        "    return sentenceArray\n",
        "  \n",
        "  def sentenceArray_to_OHE(self, sentenceArray):\n",
        "    sentenceArray_OHE = to_categorical(sentenceArray)\n",
        "    (req_rows, req_cols) = (self.length_max_sentence, self.length_all_Unique_Characters)\n",
        "    (actual_rows, actual_cols) = sentenceArray_OHE.shape\n",
        "    sentenceArray_OHE = np.concatenate((sentenceArray_OHE, np.zeros((req_rows-actual_rows, actual_cols), dtype='float32')), axis=0)\n",
        "    sentenceArray_OHE = np.concatenate((sentenceArray_OHE, np.zeros((req_rows, req_cols-actual_cols), dtype='float32')), axis=1)\n",
        "    return sentenceArray_OHE\n",
        "\n",
        "  def OHE_to_sentenceArray(self, sentence_array_OHE):\n",
        "    sentenceArray = []\n",
        "    for OHE in sentence_array_OHE:\n",
        "      if sum(OHE)!=0:\n",
        "        sentenceArray.append(argmax(OHE))\n",
        "    return sentenceArray\n",
        "  \n",
        "  def preprocess_data(self, text):\n",
        "    data = pd.DataFrame()\n",
        "    # Cleaning --------------------------\n",
        "    text = text.replace(\"\\n\", \" \") \n",
        "    for char in [' .', ' ,', ' ;', ' ?', ' !', '( ', ' )']:\n",
        "      text = text.replace(char, char.strip())\n",
        "    text = text.replace(\"<s>\", \"\")\n",
        "    \n",
        "    # =========================== CHARACTERS ===========================\n",
        "    # Unique Characters -----------------\n",
        "    self.all_Unique_Characters = list(set(text.replace(\"</s>\", \"\")))\n",
        "    self.all_Unique_Characters.sort()\n",
        "    \n",
        "    # Max Length of Unique Characters ---\n",
        "    self.length_all_Unique_Characters = len(self.all_Unique_Characters)\n",
        "    \n",
        "    # Preparing Character to Number and vice-versa -----\n",
        "    self.char_to_num = {char:num for num, char in enumerate(self.all_Unique_Characters)}\n",
        "    self.num_to_char = {val:key for key, val in self.char_to_num.items()}\n",
        "\n",
        "    # =========================== SENTENCES ===========================\n",
        "    # Sentences -------------------------\n",
        "    sentences = text.split(\"</s>\")[:-1]\n",
        "    sentences = [sentence.strip() for sentence in sentences]\n",
        "    \n",
        "    # Max Length of Sentences -----------\n",
        "    self.length_max_sentence = max([len(sentence) for sentence in sentences])\n",
        "    \n",
        "    # Preparing OHE Array Variable ------\n",
        "    #self.sentenceArray_to_OHE = np.zeros((self.length_max_sentence, self.length_all_Unique_Characters), dtype='float32')\n",
        "    \n",
        "    # =========================== DATAFRAME ===========================\n",
        "    # Storing sentences in dataframe ----\n",
        "    data['sentence'] = sentences\n",
        "    # Converting Sentence to Array Numbers ----\n",
        "    data['sentence_array'] = data['sentence'].apply(lambda x: self.sentence_to_array(x))\n",
        "    # Converting Array Numbers to One-Hot-Encoding (OHE) ----\n",
        "    data['sentence_array_OHE'] = data['sentence_array'].apply(lambda x: self.sentenceArray_to_OHE(x))\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "0JI-c16BTH7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Process Input and Target datasets**"
      ],
      "metadata": {
        "id": "fWWYjsXLK8Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = \"/content/drive/MyDrive/NLP/NLP_Assingnmnet05/data/train-05/train-source.txt\"\n",
        "train_input_data = load_data(filePath)"
      ],
      "metadata": {
        "id": "yi8TCu-bpAMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Input_LTM = Language_Translation_Model()\n",
        "Input_data = Input_LTM.preprocess_data(train_input_data[0:10000])\n",
        "Input_data.head()"
      ],
      "metadata": {
        "id": "4s2tKcYwXn1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = \"/content/drive/MyDrive/NLP/NLP_Assingnmnet05/data/train-05/train-target.txt\"\n",
        "train_target_data = load_data(filePath)"
      ],
      "metadata": {
        "id": "jEjY7j6zFB8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Output_LTM = Language_Translation_Model()\n",
        "Output_data = Output_LTM.preprocess_data(train_target_data[0:10000])\n",
        "Output_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "jW3-c8D04x5P",
        "outputId": "d53ab68e-1640-418c-a4c0-ec957a957857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  cinnte go leor, thiocfadh dóibh bás a fháil ar...   \n",
              "1  bhí sé follasach go raibh an poll sin ag foscl...   \n",
              "2  d'fhéadfadh siad bás a fháil ar a bhruach agus...   \n",
              "3  thiocfadh dóibh fosta lámh a chur ina mbás féi...   \n",
              "4  ina dhiaidh sin bhí rud éigin dochreidte agus ...   \n",
              "\n",
              "                                      sentence_array  \\\n",
              "0  [15, 21, 25, 25, 30, 17, 0, 19, 26, 0, 23, 17,...   \n",
              "1  [14, 20, 35, 0, 29, 34, 0, 18, 26, 23, 23, 13,...   \n",
              "2  [16, 2, 18, 20, 34, 13, 16, 18, 13, 16, 20, 0,...   \n",
              "3  [30, 20, 21, 26, 15, 18, 13, 16, 20, 0, 16, 36...   \n",
              "4  [21, 25, 13, 0, 16, 20, 21, 13, 21, 16, 20, 0,...   \n",
              "\n",
              "                                  sentence_array_OHE  \n",
              "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
              "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-700bab36-2ddb-43d5-82d7-2714857df88a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentence_array</th>\n",
              "      <th>sentence_array_OHE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cinnte go leor, thiocfadh dóibh bás a fháil ar...</td>\n",
              "      <td>[15, 21, 25, 25, 30, 17, 0, 19, 26, 0, 23, 17,...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bhí sé follasach go raibh an poll sin ag foscl...</td>\n",
              "      <td>[14, 20, 35, 0, 29, 34, 0, 18, 26, 23, 23, 13,...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d'fhéadfadh siad bás a fháil ar a bhruach agus...</td>\n",
              "      <td>[16, 2, 18, 20, 34, 13, 16, 18, 13, 16, 20, 0,...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thiocfadh dóibh fosta lámh a chur ina mbás féi...</td>\n",
              "      <td>[30, 20, 21, 26, 15, 18, 13, 16, 20, 0, 16, 36...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ina dhiaidh sin bhí rud éigin dochreidte agus ...</td>\n",
              "      <td>[21, 25, 13, 0, 16, 20, 21, 13, 21, 16, 20, 0,...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-700bab36-2ddb-43d5-82d7-2714857df88a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-700bab36-2ddb-43d5-82d7-2714857df88a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-700bab36-2ddb-43d5-82d7-2714857df88a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data = np.array([record for record in Input_data['sentence_array_OHE']])\n",
        "decoder_input_data = np.array([np.concatenate((np.zeros((record.shape[0], 1), dtype='float32'), record[:, 1:]), axis=1) for record in Output_data['sentence_array_OHE']])\n",
        "decoder_target_data = np.array([record for record in Output_data['sentence_array_OHE']])"
      ],
      "metadata": {
        "id": "NyNCet3HIGxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Preparation & Training**"
      ],
      "metadata": {
        "id": "9GtOnbg7lMMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "FDrMaNNBStcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_LSTM:\n",
        "  def __init__(self, Input_LTM, Output_LTM, num_samples=10000, latent_dim=256, batch_size = 128, epochs=1):\n",
        "    self.batch_size = batch_size\n",
        "    self.epochs = epochs\n",
        "    self.latent_dim = latent_dim\n",
        "    self.num_samples = num_samples\n",
        "    self.Input_LTM = Input_LTM\n",
        "    self.Output_LTM = Output_LTM\n",
        "\n",
        "    encoder_inputs = Input(shape=(None, self.Input_LTM.length_all_Unique_Characters))\n",
        "    encoder = LSTM(latent_dim, return_state=True) # latent_dim = 256\n",
        "    encoder_outputs, state_h, state_c = encoder(encoder_inputs) # We discard `encoder_outputs` and only keep the states.\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    decoder_inputs = Input(shape=(None, Output_LTM.length_all_Unique_Characters))\n",
        "\n",
        "    # We set up our decoder to return full output sequences, and to return internal states as well. We don't use the return states in the training model, but we will use them in inference.\n",
        "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(Output_LTM.length_all_Unique_Characters, activation='softmax')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Defining Model ------------------\n",
        "    self.model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    # Compiling Model ------------------\n",
        "    self.model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # For Prediction ---------------------\n",
        "    self.encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_states_inputs = [Input(shape=(latent_dim,)), Input(shape=(latent_dim,))]\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    self.decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "    \n",
        "  def train(self, encoder_input_data, decoder_input_data, decoder_target_data):\n",
        "    startTime = datetime.now()\n",
        "\n",
        "    self.model.fit([encoder_input_data, decoder_input_data], \n",
        "          decoder_target_data,\n",
        "          batch_size=self.batch_size,\n",
        "          epochs=self.epochs,\n",
        "          validation_split=0.2)\n",
        "    endTime = datetime.now()\n",
        "    print(\"Training is Completed Successfully in time : \", endTime-startTime)\n",
        "    \n",
        "  def predict(self, input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = self.encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, self.Output_LTM.length_all_Unique_Characters)) # Output_LTM.length_all_Unique_Characters -> Number of output characters\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, 0] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = self.Output_LTM.num_to_char[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > self.Output_LTM.length_max_sentence):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, self.Output_LTM.length_all_Unique_Characters))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "J6pLXCo1MQO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ModelLSTM = Model_LSTM(Input_LTM, Output_LTM)"
      ],
      "metadata": {
        "id": "v8wd6D5cRkSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ModelLSTM.train(encoder_input_data, decoder_input_data, decoder_target_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59yxO-X6ShBP",
        "outputId": "be1613a1-463d-4af9-b0d7-bff13c928d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step - loss: 1.2373 - accuracy: 0.3386 - val_loss: 1.2449 - val_accuracy: 0.7151\n",
            "Training is Completed Successfully in time :  0:00:07.825980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = Input_data.loc[0, 'sentence']\n",
        "print(input_sentence)\n",
        "\n",
        "output_sentence = Output_data.loc[0, 'sentence']\n",
        "print(output_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_vFwEP1UNK4",
        "outputId": "8678eff1-d28e-441c-ae51-894ea20eb18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cinnte go leór, thiocfadh dóbhtha bás a fhagháil ar imeall an phuill udaí.\n",
            "cinnte go leor, thiocfadh dóibh bás a fháil ar imeall an phoill úd.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_record = np.array([Input_data.loc[0, 'sentence_array_OHE']])\n",
        "print(input_record.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toSxjP8HTJVD",
        "outputId": "6c6b2d70-7285-433c-c5b4-f799460f802a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 234, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sentence = ModelLSTM.predict(input_record)"
      ],
      "metadata": {
        "id": "GMYwBnfjTC4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoded_sentence)"
      ],
      "metadata": {
        "id": "u3aTzA0xTT8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_record = Output_data.loc[0, 'sentence']\n",
        "print(output_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6UNGeyETmef",
        "outputId": "3254a61c-baf7-46a3-c18b-c1850f2df5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cinnte go leor, thiocfadh dóibh bás a fháil ar imeall an phoill úd.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(decoded_sentence), len(output_record))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VgBrEcQTu1G",
        "outputId": "9416b952-eef1-4cb5-b7d9-a17fd3bb0f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "237 67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation**"
      ],
      "metadata": {
        "id": "3Tuz2u8pVUP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Input_Test data**"
      ],
      "metadata": {
        "id": "OJK02KyfVt-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = \"/content/drive/MyDrive/NLP/NLP_Assingnmnet05/data/train-05/train-source.txt\"\n",
        "train_input_data = load_data(filePath)\n",
        "\n",
        "test_Input_LTM = Language_Translation_Model()\n",
        "Input_data = test_Input_LTM.preprocess_data(train_input_data[0:10000])\n",
        "Input_data.head()"
      ],
      "metadata": {
        "id": "gN_p8kz-VWdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "el3yb98nVWfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qst140cpVWiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0QW8mbTjVWkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}